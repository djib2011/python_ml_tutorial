{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with scikit-learn\n",
    "\n",
    "> [scikit-learn](http://scikit-learn.org/) or *sklearn* is a Machine Learning library in Python. It is fully interoperable with *numpy* and *scipy*.\n",
    "\n",
    "Scikit-learn is the largest and best supported ML library in python. Its structure resembles how *scipy* is organized, i.e. in subpackages, the main of which are:\n",
    "\n",
    "- `sklearn.datasets`: Contains functions for downloading and loading several known datasets, as well as tools for creating artificial ones.\n",
    "- `sklearn`.**model_family**: All models (supervised and unsupervised) are grouped into categories or families. For example: \n",
    "    - `sklearn.dummy`: *Dummy* classifiers and regressors used for benchmarking (e.g. `DummyClassifier`, `DummyRegressor`) .\n",
    "    - `sklearn.linear_model`: Family of linear models (e.g. `LinearRegression`, `LogisticRegression`, `Lasso`, `Ridge`).\n",
    "    - `sklearn.tree`: Tree-based algorithms (e.g. `DecisionTreeClassifier`, `DecisionTreeRegressor`).\n",
    "    - `sklearn.ensemble`: Ensemble methods (e.g. `RandomForestClassifier`, `GradientBoostingClassifier`).\n",
    "    - `sklearn.naive_bayes`: Naive Bayes algorithms (e.g. `GaussianNB`).\n",
    "    - `sklearn.neighbors`: k-Nearest Neighbors implementations (e.g. `KNeighborsClassifier`, `KNeighborsRegressor`).\n",
    "    - `sklearn.neural_network`: Neural Network based algorithms (e.g. `MLPClassifier`, `MLPRegressor`).\n",
    "    - `sklearn.cluster`: Collection of clustering algorithms (e.g. `KMeans`, `DBSCAN`, `SpectralClustering`).\n",
    "- `sklearn.preprocessing`: Sub-module including multiple preprocessing options (e.g. *scaling*, *normalization*).\n",
    "- `sklearn.impute`: Classes that handle imputing missing values. \n",
    "- `sklearn.feature_selection`: Techniques for selecting or discarding features based on certain criteria.\n",
    "- `sklearn.feature_extraction`: Feature extraction algorithms.\n",
    "- `sklearn.metrics`: Implementations of a large number of performance metrics both for supervised and unsupervised learning.\n",
    "- `sklearn.model_selection`: Contains functions for splitting the data and evaluating models. \n",
    "- `sklearn.pipeline`: The *Pipeline* class which incorporates multiple steps of the ML workflow into a single object. \n",
    "- `sklearn.utils`: Includes various utilities.\n",
    "\n",
    "Through this tutorial we will get acquainted with the main functionality of scikit-learn. To do this, we'll load one of scikit-learn's datasets (which are already processed to a great extent), split it into a training and test set, train ML models on them and compare them to see which one performed the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "The first thing we'll do is to load a dataset. Scikit-learn has a submodule called `datasets` which contains many popular datasets we can use. For this tutorial we'll work with the [iris dataset](https://archive.ics.uci.edu/ml/datasets/iris). \n",
    "\n",
    "![](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Machine+Learning+R/iris-machinelearning.png)\n",
    "\n",
    "This dataset depicts a **classification** problem with $150$ samples, each having $4$ features (i.e. sepal length, sepal width, petal length and petal width). Each sample belongs to one of 3 classes (i.e. *Iris Versicolor*, *Iris Setosa* and *Iris Virginica*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()  # downloads and loads the dataset into memory in the form of a dictionary\n",
    "print(iris.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each scikit-learn dataset (including `iris`) contains 5 things:\n",
    "- `data` a numpy array containing of the dataset's training examples.\n",
    "- `feature_names` is a list containing the names of each feature.\n",
    "- `target` is an array containing the labels (or targets) for all the examples.\n",
    "- `target_names` is an array containing the names of the three target classes.\n",
    "- `DESCR` is a string containing the description of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: (150, 4)\n",
      "Labels: (150,)\n",
      "Classes: ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print('Features:', iris['data'].shape)\n",
    "print('Labels:', iris['target'].shape)\n",
    "print('Classes:', iris['target_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information on the datasets scikit-learn provides can he found [here](http://scikit-learn.org/stable/datasets/index.html#datasets).\n",
    "\n",
    "## train/test split\n",
    "\n",
    "The first thing we want to do is to **shuffle** the dataset along its rows and **split** it into two parts. The first will be used to train the classifier; we'll call this the **training set**. The second will be used to evaluate the classifier's performance on and will be referred to as the **test set**. \n",
    "\n",
    "It is crucial **not** to evaluate the classifier's performance on the training set, as they usually suffer from a problem called *overfitting*, which we will investigate later on. It is also important to first shuffle the data before splitting it, so that the test set's distribution matches the training set's.\n",
    "\n",
    "The whole procedure is depicted in the following figures. First, we shuffle and split the data (the percentages are arbitrary):\n",
    "\n",
    "![train test split](https://i.imgur.com/ZDjKu8l.png)\n",
    "\n",
    "Then we use the training set to train the model:\n",
    "\n",
    "![training phase](https://i.imgur.com/cHlSuBC.png)\n",
    "\n",
    "Finally, we evaluate the model's performance on the test set:\n",
    "\n",
    "![evaluation](https://i.imgur.com/RrrDeh3.png)\n",
    "\n",
    "Scikit-learn has a function to help us with the splitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data size:\n",
      "(150, 4) (150,)\n",
      "\n",
      "Training data size:\n",
      "(90, 4) (90,)\n",
      "\n",
      "Test data size:\n",
      "(60, 4) (60,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 13  # random seed for reproducibility\n",
    "\n",
    "# This function handles both shuffling and splitting\n",
    "train, test, train_labels, test_labels = train_test_split(iris['data'], iris['target'], test_size=0.4, random_state=seed)\n",
    "print('Full data size:')\n",
    "print(iris['data'].shape, iris['target'].shape)\n",
    "print('\\nTraining data size:')\n",
    "print(train.shape, train_labels.shape)\n",
    "print('\\nTest data size:')\n",
    "print(test.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we just shuffled and split our 150 samples into a training set (90 samples) and a test set (60 samples). Note that the labels were shuffle-split **accordingly**.\n",
    "\n",
    "## Training classifiers\n",
    "\n",
    "It's time to create a classifier. The first one we will use is [Logistic Regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). In scikit-learn all models are instances of a class called an *estimator*. This helps us a lot because most estimators share the same methods.\n",
    "\n",
    "The usual way of handling estimators in python is:\n",
    "\n",
    "```python\n",
    "from sklearn.model_family import model  # model_family is the family of classifiers that model belongs to\n",
    "\n",
    "my_model = model(...)  # as arguments we pass the values of any hyperparameters we wish to control\n",
    "\n",
    "my_model.fit(X_train, y_train)  # X_train: training data, y_train: training labels\n",
    "                                # this line handles the complete training phase\n",
    "\n",
    "preds = my_model.predict(X_test)  #  to generate predictions on the test set\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\thano\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\thano\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression  # LogisticRegression belongs to the family of linear_models\n",
    "\n",
    "clf = LogisticRegression()  # we will use the default hyperparameter settings\n",
    "\n",
    "clf.fit(train, train_labels)  # train the model. this might take a minute..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "\n",
    "OK, we've trained the model. Now we have to see how well it performs. In order to do this we must first define a **metric** (i.e. a function that evaluates the performance of our model). The simplest metric we can use in classification is **accuracy** (i.e. the number of correct predictions, over the number of total predictions). A full guide on scikit-learn metrics can be found [here](http://scikit-learn.org/stable/modules/model_evaluation.html#model-evaluation).\n",
    "\n",
    "Most metrics are scikit-learn functions that accept two arguments: `y_test` (the test set labels) and `y_pred` (the model's predictions on the test set).\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import desired_metric  # import the desired metric\n",
    "\n",
    "y_pred = my_model.predict(X_test)  # generate predictions\n",
    "\n",
    "print(desired_metric(y_test, y_pred))  # print the model's score \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "preds = clf.predict(test)\n",
    "\n",
    "print(accuracy_score(test_labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we scored 95% on the test set. While that might appear a good enough result, let's see if we can do better with other ML algorithms. Because of the way scikit-learn organizes its *estimators*, we need to know which family each *estimator* belongs to import it.\n",
    "\n",
    "Another important observation is that we can interact with each model the same way, **regardless** of how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp: 0.9833333333333333\n",
      "knn: 0.95\n",
      "dtc: 0.9333333333333333\n",
      "svc: 0.9833333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\thano\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\thano\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# We will use the default arguments for all classifiers\n",
    "mlp = MLPClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "dtc = DecisionTreeClassifier()\n",
    "svc = SVC()\n",
    "\n",
    "# Train the four classifiers\n",
    "mlp.fit(train, train_labels)\n",
    "knn.fit(train, train_labels)\n",
    "dtc.fit(train, train_labels)\n",
    "svc.fit(train, train_labels)\n",
    "\n",
    "# Evaluate the classifiers\n",
    "preds = mlp.predict(test)\n",
    "print('mlp:', accuracy_score(test_labels, preds))\n",
    "preds = knn.predict(test)\n",
    "print('knn:', accuracy_score(test_labels, preds))\n",
    "preds = dtc.predict(test)\n",
    "print('dtc:', accuracy_score(test_labels, preds))\n",
    "preds = svc.predict(test)\n",
    "print('svc:', accuracy_score(test_labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Complex classifiers usually have several **hyperparameters**; parameters that affect the behaviour of the classifier, which we must select in order to achieve the best results. The classifiers we trained above were initialized with default values for their hyperparameters, so their performance was probably **unoptimized**. The selection of hyperparameters can either be **empirical** or through **trial and error**.\n",
    "\n",
    "We'll start by trying to optimize the kNN classifier by choosing the best value of $k$. The most intuitive way of doing so is through a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy 96.67% for k=1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn_accuracies = []\n",
    "for k in range(1, 22, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(train, train_labels)\n",
    "    knn_accuracies.append(accuracy_score(test_labels, knn.predict(test)))\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(7, 5))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "# Draw figure\n",
    "ax.plot(range(1, 22, 2), knn_accuracies)\n",
    "\n",
    "# Aesthetic parameters\n",
    "ax.set_xticks(range(1, 22, 2))\n",
    "\n",
    "ax.set_xlabel('$k$')\n",
    "ax.set_ylabel('accuracy')\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "ax.set_title('kNN accuracy on different values of k')\n",
    "\n",
    "print('Best accuracy {:.2f}% for k={}'.format(max(knn_accuracies)*100, list(range(1, 22, 2))[np.argmax(knn_accuracies)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure above is called **hyperparameter tuning** and can usually improve the performance of the classifier. This is even more important for more complex classifiers with multiple hyper-parameters. For example [Multi-Layer Perceptrons](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier) have a plethora of hyper-parameters which we might want to tune. We'll try to select the best *hidden layer size* and *activation*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for hidden in [(10,), (20,), (50,), (100,), (200,)]:  # consider hidden layer sizes of 10, 20, 50, 100 and 200\n",
    "    for activation in ['logistic', 'relu', 'tanh']:  # consider 'logistic' (sigmoid), 'relu' and 'tanh' activation functions\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=hidden, activation=activation)\n",
    "        mlp.fit(train, train_labels)\n",
    "        accuracies.append(accuracy_score(test_labels, mlp.predict(test)))\n",
    "\n",
    "print('Best accuracy: {:.2f}%'.format(max(accuracies)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing ML models through *for* loops isn't the most efficient way. The best parameters are hard to identify, the computer makes no use of parallelization and the code isn't as *elegant* as possible. \n",
    "\n",
    "## Grid search\n",
    "\n",
    "Scikit-learn offers an easier, scalable and more elegant way of performing hyperparameter optimization, called [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV). This function takes two main arguments: an estimator (or pipeline) and a *grid* of parameters we want the grid search to consider. The grid could be one of two things:\n",
    "\n",
    "- A dictionary with the hyperparameter names as its keys and a list of values as the corresponding dictionary value:\n",
    "```python\n",
    "grid = {'name1': [val_1a, val_1b, val_1c], 'name2': [val_2a, val_2b]}\n",
    "```\n",
    "This will force the grid search to search for **all** possible combinations of parameter values. In this case:  \n",
    "```python\n",
    "(val_1a, val_1a), (val_1a, val_2b), (val_1b, val_2a), (val_1b, val_2b), (val_1c, val_2a), (val_1c, val_2b)\n",
    "```\n",
    "\n",
    "- A list of such dictionaries:\n",
    "```python\n",
    "grid = [{'name1': [val1, val2, val3], 'name2': [val4, val5], ...},\n",
    "        {'name1': [val1, val2, val3], 'name3': [val6, val7], ...}]\n",
    "```\n",
    "This will create a grid that contains combinations from both dictionaries.\n",
    "\n",
    "After creating such a grid:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = {...}\n",
    "clf = GridSearchCV(estimator, grid)\n",
    "clf.fit(X_train, y_train)  # will search all possible combinations defined by the grid\n",
    "preds = clf.predict(X_test)  # will generate predictions based on the best configuration\n",
    "\n",
    "# In order to access the best model:\n",
    "clf.best_estimator_\n",
    "```\n",
    "\n",
    "We will reproduce the previous hyperparameter tuning we performed, through a grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 98.33%\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# configurations we searched previously\n",
    "grid = {'hidden_layer_sizes': [(10,), (20,), (50,), (100,), (200,)],\n",
    "        'activation': ['logistic', 'relu', 'tanh']}\n",
    "# the keys of the dictionary should have the same names as the arguments of the estimator\n",
    "\n",
    "clf = GridSearchCV(mlp, grid, cv=2) # the cv parameter will be explained in the next tutorial\n",
    "clf.fit(train, train_labels)\n",
    "print('Best accuracy: {:.2f}%'.format(accuracy_score(test_labels, clf.predict(test))*100))\n",
    "print(clf.best_estimator_)  # print the best configuration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
